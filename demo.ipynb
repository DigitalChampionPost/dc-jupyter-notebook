{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &#127794; Digital Champion - Python Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#128210; Inhaltsverzeichnis\n",
    "* [Entscheidungsbäume](#eb)\n",
    "* [Data Preprocessing](#dp)\n",
    "* [Konstruktion: Entscheidungsbaum](#dt)\n",
    "* [Cost-Complexity Pruning](#ccp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#169; Quellen:\n",
    "&#128190; **Daten:** https://archive.ics.uci.edu/dataset/45/heart+disease \n",
    "<br>\n",
    "&#128252;  **Video:** https://youtu.be/q90UDEgYqeI?list=PLBq2sVJiEBvA9rPo3IEQsJNI4IJbn81tB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#128161; Weitere Informationen:\n",
    "\n",
    "``` Decision Trees: ``` &nbsp; https://www.youtube.com/watch?v=7VeUPuFGJHk&t=0s\n",
    "<br>\n",
    "``` Cross Validation: ``` &nbsp; https://www.youtube.com/watch?v=fSytzGwwBVw&t=0s\n",
    "<br>\n",
    "``` Confusion Matrix: ``` &nbsp; https://www.youtube.com/watch?v=Kdsp6soqA7o&t=0s\n",
    "<br>\n",
    "``` Cost-Complexity Pruning: ``` &nbsp; https://www.youtube.com/watch?v=D0efHEJsfHo&t=0s\n",
    "<br>\n",
    "``` Bias and Variance and Overfitting: ``` &nbsp; https://www.youtube.com/watch?v=EuBBz3bI-aA&t=0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Einführung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebooks sind interaktive Entwicklungsumgebungen, die es ermöglichen, Code, Visualisierungen und Text in einer einzigen Umgebung zu kombinieren. Sie werden häufig für die Datenanalyse, den Code-Austausch und die Dokumentation verwendet. Mit Jupyter Notebooks können Python-Codezellen ausgeführt und die Ergebnisse sofort angezeigt werden. In diesem Jupyter-Notebook werden wir ```Entscheidungsbäume``` betrachten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"eb\"></a>\n",
    "## 2 Entscheidungsbäume Theorie & Aufgabenstellung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Was ist ein Entscheidungsbaum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entscheidungsbäume sind eine Methode zur automatischen Klassifizierung von Datenobjekten und damit zur Lösung von Entscheidungsproblemen. Ein Entscheidungsbaum besteht immer aus einem Wurzelknoten (root node) und beliebig vielen inneren Knoten (split node) sowie mindestens zwei Blättern (leaf node). Dabei repräsentiert jeder Knoten eine logische Regel und jedes Blatt eine Antwort auf das Entscheidungsproblem. Im Folgenden ist ein Beispiel für einen Entscheidungsbaum abgebildet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/dt-example-new.png \"Beispiel Entscheidungsbaum\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem abgebildeten Entscheidungsbaum wollen wir mit den Informationen von ```income_usd``` und ```with_mortage``` herausfinden, ob eine Person eine Versicherung hat.\n",
    "\n",
    "Die folgenden Informationen sind üblicherweise im Entscheidungsbaum abgebildet:\n",
    "* **gini:** Der Gini-Index beschreibt, wie gut ein Knoten verschiedene Klassen separiert. Der Wert ist immer zwischen 0 und 1. Je kleiner der Gini-Index ist desto besser. Bei der Konstruktion des Entscheidungsbaumes kann der Gini-Index berechnet werden. Es wird immmer die logische Regel gewählt, welche den besten Gini-Index aufweist.\n",
    "* **samples:** Dieser Wert beschreibt die Anzahl Testobjekte, welche für den Split eines spezifischen Knoten zur Verfügung stehen. Wir sehen beispielsweise, dass für die Konstruktion dieses Baumes 24 Testobjekte verwendet werden. Weiter sehen wir, dass der erste Knoten die 24 Testobjekte in eine Gruppe mit 13 Testobjekte und eine Gruppe mit 11 Testobjekten aufteilt.\n",
    "* **value:** Value beschreibt, wie die Aufteilung der 'samples' im Knoten aussieht. Der Wert '[15, 9]' im ersten Knoten beschreibt beispielsweise, dass von 24 Testobjekten 15 keine Versicherung und 9 Testobjekte eine Versicherung haben.\n",
    "* **class:** Dieser Wert steht für die Klasse, die ein spezifischer Knoten erhält. Beispiel: Im ersten Knoten sehen wir, die Klasse 'No insurance', da von den 24 Testobjekten mehr 'No Insurance' (15) haben, als 'Has Insurance' (9). Anhand der Farbe kann ebenfalls die Klasse abgelesen werden. Je röter ein Knoten ist, je mehr gehört er zur Klasse 'No Insurance' und je blauer ein Knoten ist, je mehr gehört er zur Klasse 'Has Insurance'.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>INFO:</b> \n",
    "Wie kann man einen Entscheidungsbaum lesen bzw. wie klassifizert der Entscheidungsbaum neue Datenobjekte:\n",
    "\n",
    "- Wir starten immer beim Wurzelknoten, d.h. ganz oben im Entscheidungsbaum\n",
    "\n",
    "- Wenn die logische Regel im Knoten für das Datenobjekt erfüllt ist, geht man nach links und wenn sie nicht erfüllt ist, geht man nach rechts\n",
    "\n",
    "- Wir durchlaufen den Baum solange, bis wir in einem 'Blatt' ankommen. Das 'class' Attribute im Blatt beschreibt die Klasse des neuen Datenobjekts \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <b>AUFGABE 1:</b> Bestimme die Klasse der beiden nachfolgeden Datenobjekte anhand des oben abgebildeten Entscheidungsbaums:\n",
    "\n",
    "- Datenobjekt 1: income_usd = 100'000; with_mortage = 0\n",
    "\n",
    "- Datenobjekt 2: income_usd = 73'000; with_mortage = 1\n",
    "\n",
    "-> Lösungen zu [Aufgabe 1](#l1)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene Lösung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Aufgabenstellung\n",
    "\n",
    "In diesem Jupyter-Notebook arbeiten wir mit dem ['heart-disease'](https://archive.ics.uci.edu/dataset/45/heart+disease) Datenset. Das Datenset ist eine Tabelle mit 14 Spalten und 303 Zeilen. Eine kurze Beschreibung der verschiedenen Spalten:\n",
    "* age: Alter\n",
    "* sex: Mann/Frau\n",
    "* cp: chest pain type (typische Angina, atypische Angina, nicht-anginös, asymptomatisch)\n",
    "* restbp: resting blood pressure (Ruheblutdruck (in mm Hg bei Aufnahme ins Krankenhaus))\n",
    "* chol: Serumcholesterin in mg/dl\n",
    "* fbs: wenn der Nüchternblutzucker > 120 mg/dl liegt\n",
    "* restecg: Ergebnisse des Ruhe-Elektrokardiogramms (normal, STT-Anomalie, LV-Hypertrophie)\n",
    "* thalach: maximale Herzfrequenz erreicht\n",
    "* exang: Belastungsangina (Richtig/Falsch)\n",
    "* oldpeak: ST-Depression durch körperliche Betätigung im Vergleich zur Ruhe\n",
    "* slope: die Steigung des Spitzenbelastungs-ST-Segments\n",
    "* ca: Anzahl der großen Gefäße (0-3), gefärbt durch Fluoroskopie\n",
    "* thal: normal; behobener Defekt; reversibler Defekt\n",
    "* hd: Art der Herzerkrankung\n",
    "\n",
    "Eine Zeile in dieser Tabelle entspricht genau einem Testobjekt. Das heisst, wir arbeiten mit 303 Testobjekten. Unser Ziel ist es, mit diesen 303 Testobjekten ein Modell zu generieren, welches neue Datenobjekte klassifizieren und somit bestimmen kann, ob eine Herzerkrankung vorliegt oder nicht. Im Modell nutzen wir die folgenden Features um die Zielvariable (hd) vorherzusagen:\n",
    "<br>\n",
    "<br>\n",
    "```age```, ```sex```, ```cp```, ```restbp```, ```chol```, ```fbs```, ```restecg```, ```thalach```, ```exang```, ```oldpeak```, ```slope```, ```ca```, ```thal```\n",
    "\n",
    "Wir verwenden einen Entscheidungsbaum für die Klassifikation von Herzkrankheiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"dp\"></a>\n",
    "## 3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wichtig: Diese beiden Zeilen müssen zwingend ausgeführt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lädt unser Datensatz herunter\n",
    "!git clone https://github.com/LearningFridayPost/dc-jupyter-notebook.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ändert working directory, sodass Daten korrekt eingelesen werden können.\n",
    "%cd dc-jupyter-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Read data\n",
    "\n",
    "Bei jedem neuen Python-Projekt überlegen wir uns, welche Python-Bibliotheken wir verwenden möchten. Eine Python-Bibliothek ist ein wiederverwendbarer Codeblock, den wir in einem Programme bzw. Projekt einbinden können. Das Einbinden von solchen Codeblocks ist einiges schneller als den Code selber zu schreiben.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>INFO:</b> \n",
    "Wenn wir in Python programmieren, ist es wichtig zu wissen, dass alles was hinter einem '#' steht kein Code ist, sondern nur ein Kommentar um den Code zu beschreiben. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install pandas numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "# pandas: Daten lesen und bearbeiten\n",
    "import pandas as pd\n",
    "# numpy: berechnen von KPIs\n",
    "import numpy as np\n",
    "# plt: ploten von Grafiken\n",
    "import matplotlib.pyplot as plt\n",
    "# DecisionTreeClassifier: Modellierungskit für Entscheidungsbäume\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# plot_tree: Entscheidungsbaum als Grafik ploten\n",
    "from sklearn.tree import plot_tree\n",
    "# train_test_split: Hilfe um Testobjekte in Training- bzw. Testset zu splitten\n",
    "from sklearn.model_selection import train_test_split\n",
    "# cross_val_score: Kreuzvalidierung\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# confusion_matrix: Konfusionsmatrix ploten\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# ConfusionMatrixDispla: Konfusionsmatrix ploten\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# accuracy_score: berechne die Accuracy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>INFO:</b>  In Python kann man mit Hilft des '=' Operatros Daten in einer Variable speichern. Wenn wir beispielsweise die Zahl 5 in der Variable 'a' speichern möchten, können wir das mit dem folgenden Code machen:\n",
    "<br><br>\n",
    "a = 5 \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'heart-disease' Daten einlesen und in 'df' als Tabelle speichern\n",
    "df = pd.read_csv('data/processed.cleveland.data', header=None, sep=',', encoding='latin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <b>AUFGABE 2:</b> \n",
    "Speichere die Daten in der Variable 'df_start'\n",
    "    \n",
    "-> Lösungen zu [Aufgabe 2](#l2)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene Lösung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion .head() zeigt, wie die ersten fünf Spalten in der Tabelle aussehen\n",
    "df_start.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir sehen, dass die Spalten keine Namen haben\n",
    "# Mit dem untenstehenden Code könenen wir den Spalten Namen geben\n",
    "column_name_list = ['age', 'sex', 'cp', 'restbp', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'hd']\n",
    "df_start.columns = column_name_list\n",
    "df_start.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fehlenden Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Attribut .dtypes zeigt, welchen Datentyp die Spalten haben:\n",
    "# float64: Daten mit Zahlen mit Nachkommastellen (z.B. Körpergrösse)\n",
    "# object: Daten mit Kategorien (z.B. Mann / Frau)\n",
    "# int64: Daten mit ganzen Zahlen (z.B. Alter könnte als int gespeichert werden)\n",
    "df_start.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenn wir den Spaltennamen in eckige Klammer schreiben, z.B. ['Spaltenname'], erhalten wir die Werte dieser Spalte\n",
    "df_start['ca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion .unique() zeigt allte einzigartigen Elemente in der Spalte 'ca'\n",
    "df_start['ca'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir sehen, dass die Daten ein '?' enthalten\n",
    "# Dieses '?' möchten wir entfernen, da ein Entscheidungsbaum mit fehlenden Daten nicht umgehen kann\n",
    "# [Tabellenname['Spaltenname'] == 'zu prüfender Text'] so kann eine Tabelle nach einem spezifischen Spaltenwert gefiltert werden\n",
    "df_start[df_start['ca'] == '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>INFO:</b> Die wichtigsten Vergleichsoperatoren:\n",
    "    \n",
    "* ==: zu vergleichendes Element muss den gleichen Inhalt haben\n",
    "* !=: zu vergleichendes Element darf nicht den gleichen Inhalt haben\n",
    "* \\>=: zu vergleichende Zahl muss gleich grösser sein\n",
    "* <=: zu vergleichende Zahl muss gleich kleiner sein\n",
    "     \n",
    "     </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Funktion len() gibt als Output an, wie viele Zeilen eine Tabelle enthält\n",
    "len(df_start[df_start['ca'] == '?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <b>AUFGABE 3:</b> \n",
    "Wir haben gesehen, dass nur 4 Testobjekte in der Spalte 'ca' ein '?' enthalten. Weil es nur so wenige Testobjekte sind, wollen wir diese aus unserer 'df_start' Tabelle rausfiltern und die neue Tabelle unter 'df_no_missing_1' speichern.\n",
    "\n",
    "-> Lösungen zu [Aufgabe 3](#l3)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene Lösung:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <b>AUFGABE 4:</b> \n",
    "Auch in der Spalte 'thal' hat es fehlende Daten. Prüfe wie viele Testobjekte fehlende Daten in der Spalte 'thal' haben. Filtere die betroffenen Testobjekte aus der Tabelle 'df_no_missing_1' raus und speichere die neue Tabelle unter 'df_no_missing_2'\n",
    "\n",
    "-> Lösungen zu [Aufgabe 4](#l4)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene Lösung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier prüfen wir, ob wir alle '?' entfernt haben\n",
    "df_no_missing_2['ca'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier prüfen wir, ob wir alle '?' entfernt haben\n",
    "df_no_missing_2['thal'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Ausreisser\n",
    "\n",
    "Bei den folgenden Spalten vermuten wir Ausreisser (Outliers):\n",
    "* tahlach\n",
    "* slope\n",
    "\n",
    "Eine Möglichkeit Daten auf Ausreisser zu prüfen sind Boxplots. Boxplots zeigen wie die Daten verteilt sind.\n",
    "\n",
    "![alt text for screen readers](./pictures/boxplot-new.png \"Beispiel Boxplot\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .boxplot(Spaltenname) plottet einen Boxplot einer Tabellenspalte\n",
    "df_no_missing_2.boxplot('slope')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .boxplot(Spaltenname) plottet einen Boxplot einer Tabellenspalte\n",
    "df_no_missing_2.boxplot('thalach')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass es in der Spalte 'thalach' einen Outlier hat. Potenziell sollte man die Outlier möglichst entfernen, damit man eine saubere Datengrundlage hat. Die Details zu diesem Thema gehen aber über den Scope dieser Einführung hinaus und wir belassen die Daten wie sie sind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Daten formatieren\n",
    "In einem nächsten Schritt müssen wir die Daten in zwei Teile auftrennen. Alle Features kommen in den Vektor 'X'. Die Werte der Zielvariablen kommen in den Vektor 'y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit .copy() kopieren wir das Resultat in eine neue Variable\n",
    "df_clean = df_no_missing_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in diesem Schritt speichern wir alle Features in 'X'\n",
    "# .drop('Spaltenname', axis=1) kann verwendet werden um eine Spalte zu entfernen\n",
    "# mit .copy() kopieren wir das Resultat in eine neue Variable\n",
    "X = df_clean.drop('hd', axis=1).copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in diesem Schritt speichern wir alle Zielvariablen in 'y'\n",
    "y = df_clean['hd'].copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wissen bereits, dass jede Spalte einen spezifischen Datentyp hat. Basierend auf diesem Wissen müssen wir die Daten in 'X' weiter formatieren.\n",
    "\n",
    "Wir haben mit allen kategorischen Daten in dieser Tabelle folgendes Problem:\n",
    "* Entscheidungsbäume unterstützen keine Featrues mit kategorischen Datentypen. Eine Lösung wäre, Features mit kategorische Daten in Zahlen umzuwandeln (z. B. Biene = 1, Elefant = 2, Vogel = 3). Dies funktioniert jedoch nicht. Wenn wir dies tun würden, würde der Baum annehmen, dass Elefanten und Bienen (|1-2|=1) ähnlicher sind als Bienen und Vögel (|1-3|=2). Dies aus dem Grund, dass die logischen Regeln in den Knoten der Entscheidungsbäume, die Testobjekte immer auf einen spezifische Bereich prüfen (z.B. >= oder <=).\n",
    "\n",
    "One-Hot-Encoding als Lösung für das Problem:\n",
    "* Wir erstellen für jede einzelne Kategorie in einer Spalte bzw. Feature eine eigene separate 'Kategoriespalte' in der 'X' Tabelle. Für jede 'Kategoriespalte' geben wir den Wert 0 oder 1 ein, basierend auf der Tatsache, ob dieses bestimmte Merkmal für den Datensatz wahr ist (1) oder nicht (0). Diese Technik wird „One-Hot-Encoding“ genannt. Das heisst wir machen aus einem Feature viele. Der Entscheidungsbaum kann mit Features welche nur 0 oder 1 enthalten umgehen (z.B. Feature 1 >= 0.5).\n",
    "\n",
    "Die folgenden Features enthalten kategorische Daten:\n",
    "* 'cp'\n",
    "* 'restecg'\n",
    "* 'slope'\n",
    "* 'thal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# welche eindeutigen kategorischen Features sind in 'cp' vorhanden?\n",
    "X['cp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit pd.get_dummies(Tabellenname, columns=[Spaltenname1, Spaltenname2], dtype=int) kann man spezifische Features One-Hot-Encoden\n",
    "# One-Hot-Encoding für die Saplte 'cp'\n",
    "pd.get_dummies(X, columns=['cp'], dtype=int).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <b>AUFGABE 5:</b> \n",
    "\n",
    "Die folgenden Features in der Tabelle 'X' müssen One-Hot-Encoded werden:\n",
    "* 'cp'\n",
    "* 'restecg'\n",
    "* 'slope'\n",
    "* 'thal'\n",
    "\n",
    "Speichere die neue Tabelle in 'X_encoded'.\n",
    "<br>\n",
    "<br>-> Lösungen zu [Aufgabe 5](#l5)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene Lösung:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir sehen, dass y diverse Werte enthält\n",
    "# y > 0 heisst, es ist eine Herzkrankheit vorhanden (1, 2, 3, 4 stehen für spezifische Krankheiten)\n",
    "# y = 0 heisst, es ist keine Herzkrankheit vorhanden\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da wir nur herausfinden wollen, ob eine Krahnkeit vorhanden ist oder nicht, ersetzen wird die Werte 2, 3 und 4 mit 1 -> die neue Bedeutung der y Werte findet sich untenstehend\n",
    "# y = 0 heisst, es ist keine Herzkrankheit vorhanden\n",
    "# y = 1 heisst, es ist eine Herzkrankheit vorhanden\n",
    "# als erstes definieren wir eine Bedingung\n",
    "y_not_zero_index = y > 0\n",
    "# [Bedingung] so filtern wir alle Elemente die einer Bedingung entsprechen\n",
    "y[y_not_zero_index] = 1\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nächsten Schritt unterteilen wir unsere Daten in ein 'Trainings-' und in ein 'Testset':\n",
    "- Trainingsset: Wird verwendet, um einen Baum auf spezifische Testobjekte zu modellieren, trainieren und ihm die spezifischen Eigenschaften eines Datensatzes mit Testobjekten beizubringen\n",
    "- Testset: Wird verwendet, um den Baum zu testen und zu kontrollieren, wie gut er mit neuen Datenobjekten abschneidet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit der Funktion train_test_split() kann man die Daten in ein Testset bzw. Trainset teilen\n",
    "# Standardmäßig sind im Testset 25% der Daten vorhanden und im Trainingsset 75%\n",
    "# wir sehen, dass train_test_split() 4 Tabellen generiert\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/train_test_split.png \"Beispiel Boxplot\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"dt\"></a>\n",
    "## 4 Entscheidungsbaum\n",
    "### 4.1 Einfacher Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt konstruieren wir den Entscheidungsbaum aufgrund unserer Testobjekte.\n",
    "\n",
    "Ein generellese Vorgehen für die Kontruktion ist untenstehend beschrieben:\n",
    "1. Erstellen Sie einen einfachen Entscheidungsbaum als Basismodell\n",
    "2. Versuche den einfachen Entscheidungsbaum durch Optimierung der verschiedenen Parameter zu verbessern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTressClassifier() übernimmt für uns das erstellen eines Entscheidungsbaumes\n",
    "clf_dt_e = DecisionTreeClassifier(random_state=42)\n",
    "# .fit() weist dem Entscheidungsbaum ein Trainingsset zu\n",
    "clf_dt_e = clf_dt_e.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mit den folgenden Zeilen können wir einen Entscheidungsbaum erstellen\n",
    "# hier wird die grösse des plots definiert (15 steht für die Breite und 7.5 steht für die Höhe)\n",
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# plot_tree() übernimmt das visualisieren eines Entscheidungsbaumes für uns\n",
    "# 'decision_tree' steht für den Entscheidungsbaum der visualisiert werden soll\n",
    "plot_tree(decision_tree=clf_dt_e,\n",
    "          # 'filled=True' so werden die Knoten mit Farben gefüllt\n",
    "          filled=True,\n",
    "          # 'class_names=[\"No HD\", \"Yes HD\"]' wo wir definiert was in jedem Knoten unter 'class' stehen soll\n",
    "          class_names=[\"No HD\", \"Yes HD\"],\n",
    "          # 'feature_names=X_encoded.columns' muss mitgegeben werden, dass die Features im Plot korrekt bezeichnet werden\n",
    "          feature_names=list(X_encoded.columns))\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .get_n_leaves() zeigt wie viele Bläter ein Entscheidungsbaum hat\n",
    "clf_dt_e.get_n_leaves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem ersten Schritt haben wir einen 'einfachen' Entscheidungsbaum gebaut. Jetzt wollen wir sehen, wie gut dieser Entscheidungsbaum, welchen wir mit den Trainingsset trainiert haben, Klassifizierungen im Testset vornehmen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .predict(Tabellenname) kann für Klassifizierungen gebraucht werden\n",
    "# als Input muss dieser Funktion ein Tabellenname mitgegeben werden -> die Tabelle muss die Test-Features enthalten\n",
    "predictions = clf_dt_e.predict(X_test)\n",
    "# der Output ist eine Liste mit den Klassifizierungen (0: No HD; 1: Yes HD)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem nächsten Schritt wollen wir prüfen, ob diese Klassifizierungen richtig oder falsch sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix() bietet uns eine Möglichkeit für so eine Prüfung\n",
    "# 'y_true' -> Liste der korrekten Klassifizierungen\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      # 'y_pred' -> Liste der vogenommenen Klassifizierungen\n",
    "                      y_pred=predictions,\n",
    "                      # 'labels' -> Klassen von clf_dt mitgeben\n",
    "                      labels=clf_dt_e.classes_)\n",
    "\n",
    "# ConfusionMatrixDisplay() ist eine Möglichkeit die Confusion-Matrix 'cm' zu visualisieren\n",
    "# 'confusion_matrix' -> Confusion-Matrix die visualisiert werden soll\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              # 'display_labels' -> welche Labels sollen auf der Visualisierung dargestellt werden\n",
    "                              display_labels=['Does not have HD', 'Has HD'])\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die oben abgebildete Grafik zeigt eine Confusion-Matrix. Wie lesen wir diese:\n",
    "- 31: Haben keine Herzkrankheit -> Diese 31 haben wir korrekt klassifiziert <br>\n",
    "- 11: Haben keine Herzkrankheit -> Diese 11 haben wir falsch klassifiziert <br>\n",
    "- 26: Haben eine Herzkrankheit -> Diese 26 haben wir korrekt klassifiziert <br>\n",
    "- 7: Haben eine Herzkrankheit -> Diese 7 haben wir falsch klassifiziert\n",
    "\n",
    "Wie gut ein Entscheidungsbaum ist, definieren wir anhand der 'Accuracy'. Welche mit Hilfe der Confusion-Matrix berechnet werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>INFO:</b>\n",
    "\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "<br>\n",
    "<br>... bei unserem einfachen Entscheidungsbaum haben wir z.B. folgende Precision:\n",
    "<br> \n",
    "<br>Accuracy = (26 + 31) / (26 + 31 + 7 + 11) = 0.76\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_true, y_pred) liefert ebenfalls die korrekte Accuracy\n",
    "accuracy_score(y_true=y_test,\n",
    "               y_pred=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ccp\"></a>\n",
    "### 4.2 Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text for screen readers](./pictures/ccp.png \"Pruning\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben einen 46-blättrigen Entscheidungsbaum konstruiert. Dieser Entscheidungsbaum ist auf unsere Testdaten überangepasst. Das heisst, er funktioniert sehr gut für die Klassifizierung von unseren Testdaten aber weniger gut für die Klassifizierung von neuen Daten.\n",
    "\n",
    "Dieses Problem können wir lösen, indem wir verschiedene Arten von Parametern verwenden (z. B. 'max_ Depth' oder 'min_samples') und den Entscheidungsbaum vereinfachen (weniger Blätter). Diesen Prozess nennt man 'Pruning'.\n",
    "\n",
    "'Cost Complexity Pruning' ist eine spezifische Methode, um einen kleineren Baum zu finden, der bessere Ergebnisse mit den Testdaten liefert. Wir schauen, ob kleinere Teil-Entscheidungsbäume (Baum mit 38 Blätter, Baum mit 37 Blätter, etc.) bessere Ergebnisse liefern als grössere. Damit kleinere Bäume mit grösseren Bäumen verglichen werden können, verwenden wir 'alpha' als eine Art Penalty, der das Ergebniss von kleineren Bäumen verbessert (Überanpassung kontra. Genauigkeit im Testdatenset).\n",
    "\n",
    "Eine genauere Anleitung zum 'Cross Complexity Pruning' findet ihr [hier](#anhang_1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>INFO:</b>\n",
    "\n",
    "Die Werte von 'alpha' sind wie folgt zu interpretieren:\n",
    "- 0: Der Entscheidungsbaum ist nicht geprunt (maximale Grösse)\n",
    "- je grösser 'alpha' desto einfacher (weniger Blätter) ist der Entscheidungsbaum\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .cost_complexity_pruning_path(tabelle_features_train, tabelle_ergebnisse_train) ist ein Algorithmus\n",
    "# der als Ergebniss wichtige 'alpha' Parameter liefert, welche es zu Überprüfen gilt\n",
    "path = clf_dt_e.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7.5), dpi=600)\n",
    "\n",
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.00541298\n",
    "value_alpha = 0.00541298\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_new = DecisionTreeClassifier(random_state=0,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_new.fit(X_train, y_train)\n",
    "\n",
    "# plote den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_new,\n",
    "          filled=True,\n",
    "          class_names=[\"No HD\", \"Yes HD\"],\n",
    "          feature_names=list(X_encoded.columns))\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <b>AUFGABE 6:</b> \n",
    "\n",
    "Kontruiere und plote drei verschiedene Entscheidungsbäume mit verschiedenen 'alpha' Values. Für die Konstruktion kannst du den obigen Code verwenden bzw. kopieren.\n",
    "    \n",
    "Bitte stelle sicher, dass du die Entscheidungsbäume in den folgenden Variablen abspeicherst:\n",
    "- clf_dt_1\n",
    "- clf_dt_2\n",
    "- clf_dt_3\n",
    "\n",
    "-> Lösungen zu [Aufgabe 6](#l6)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dein Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# für den konstruierten Entscheidungsbaum 'clf_dt' wollen wir die Confusion-Matrix plotten, um zu sehen, wie gut er performt\n",
    "# Klasifizierungen\n",
    "predictions = clf_dt_new.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt_new.classes_)\n",
    "\n",
    "# ploten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['Does not have HD', 'Has HD'])\n",
    "\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <b>AUFGABE 7:</b> \n",
    "\n",
    "Plote die Confusion-Matrix für die in Aufgabe 6 kosnstruierten Entscheidungsbäume. Für die Plots kannst du den obigen Code verwenden bzw. kopieren.\n",
    "<br>\n",
    "<br>-> Lösungen zu [Aufgabe 7](#l7)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dein Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben jetzt gesehen, dass je nach 'alpha' die Ergebnisse schlechter oder besser werden. Die Frage ist jetzt, wie finden wir auf eine einfache Art dasjenige 'alpha', bei welchem die Ergebnisse am besten sind. Der Code, der uns hilft das beste 'alpha' zu finden, findet ihr untenstehend.\n",
    "\n",
    "Das beste Ergenbiss definieren wir in diesem Kontext anhand der 'Accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit [:-1] entfernen wir den grössten 'alpha' Wert (das grösste 'alpha' hat keine Blätter)\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "# [] steht für eine leere Liste in welche Daten gespeichert werden können\n",
    "clf_dts = []\n",
    "\n",
    "# for -> wir führen einen Code mehrmals hintereinander aus\n",
    "# for ccp_alpha in ccp_alphas -> bedeutet für jeden Wert in 'ccp_alphas' führen wir die nachfolgenden Zeilenn 1x aus\n",
    "# 'ccp_alpha' nimmt für jede Durchführung einen anderen Wert aus 'ccp_alphas' an\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    # definiere den Entscheidungsbaum\n",
    "    clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    # .append(name_daten) fügt den definierten Entscheidungsbaum der leeren Liste hinzu\n",
    "    clf_dts.append(clf_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt haben wir eine Liste, welche für jeden 'alpha' Wert den entsprechenden Entscheidungsbaum enthält. Was wir jetzt noch tun müssen, ist die 'Accuracy' in Abhängigkeit für die 'alpha' Werte zu plotten.\n",
    "\n",
    "Wir tun dies mit dem untenstehenden Code.\n",
    "\n",
    "Die Erstellung eines solchen Plottes geht über den Scope dieser kurzen Einführung hiaus. Wie der Plot zustande kommt, ist nicht Teil dieser Einführung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit diesem Code plotten wir 'Accuracy' in Abhängigkeit zu 'alpha' (für Testdaten und Trainingsdaten)\n",
    "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
    "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_title('Accuracy vs alpha for training and testing sets')\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label='train', drawstyle='steps-post')\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label='test', drawstyle='steps-post')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im obigen Plot finden wir die nötigen Informationen, welche wir brauchen um das beste 'alpha' zu finden.\n",
    "\n",
    "Von Interesse ist vorallem die orange Linie (Testdaten).\n",
    "\n",
    "Bei der Auswahl des besten 'alpha' achten wir auf die folgenden zwei Punkte:\n",
    "1. Die 'Accuracy' soll möglichst gross sein\n",
    "\n",
    "Unter anbetracht des aufgeführten Punktes, ist das optimale 'alpha' also der viertletzte Punkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# um den drittletzten Punkt zu finden rufen wir nochmals die Liste mit den 'alpha' Werten auf\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimales 'alpha'\n",
    "alpha_opt = 0.01642461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> <b>AUFGABE 8:</b> \n",
    "\n",
    "Konstruiere mit 'alpha_opt' einen Entscheidungsbaum, plotte diesen und vergleiche die 'Accuracy' dieses Entscheidungsbaumes mit der 'Accuracy' des anfänglich erhaltenen einfachen Entscheidungsbaumes.\n",
    "<br>\n",
    "<br>-> Lösungen zu [Aufgabe 8](#l8)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dein Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"anhang_1\"></a>\n",
    "### Anhang 1: Anleitung Cross Complexity Pruning\n",
    "\n",
    "Der Algorithmus zur Kostenkomplexitätsbeschneidung folgt in der Regel diesen Schritten:\n",
    "\n",
    "1. Erstellen Sie einen anfänglichen Entscheidungsbaum mit einem Trainingsdatensatz unter Berücksichtigung aller verfügbaren Attribute und Merkmale.\n",
    "2. Bewerten Sie die Klassifikationsleistung des Entscheidungsbaums anhand eines separaten Validierungsdatensatzes.\n",
    "3. Berechnen Sie für jeden internen Knoten des Entscheidungsbaums seine potenziellen Kosten in Bezug auf die fehlerhafte Klassifizierung oder andere Metriken.\n",
    "4. Weisen Sie jedem internen Knoten eine Kostenkomplexitätswertung zu, die in der Regel als Summe seiner Kosten für fehlerhafte Klassifizierung und eines Strafterms berechnet wird, der proportional zur Anzahl der absteigenden Blattknoten ist.\n",
    "5. Beginnend beim Wurzelknoten beschneiden Sie iterativ den Knoten mit der niedrigsten Kostenkomplexitätswertung und erstellen eine Reihe von kleineren Entscheidungsbäumen.\n",
    "6. Bewerten Sie die Klassifikationsleistung jedes beschnittenen Entscheidungsbaums anhand des Validierungsdatensatzes.\n",
    "7. Wählen Sie den beschnittenen Baum mit der besten Leistung aus, die oft anhand der Genauigkeit oder einer anderen geeigneten Metrik gemessen wird.\n",
    "8. Optional können Sie den ausgewählten Baum weiter beschneiden, indem Sie den Komplexitätsparameter α optimieren und die Schritte 5-7 wiederholen.\n",
    "9. Der endgültige beschnittene Entscheidungsbaum wird erzielt, wenn durch zusätzliches Beschneiden keine weiteren Verbesserungen der Leistung erzielt werden können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lösungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"l1\"></a>\n",
    "### Lösung Aufgabe 1\n",
    "\n",
    "Klassen:\n",
    "- Datenobjekt 1 = 'Has Insurance'\n",
    "- Datenobjekt 2 = 'Has Insurance' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"l2\"></a>\n",
    "### Lösung Aufgabe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"l3\"></a>\n",
    "### Lösung Aufgabe 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing_1 = df_start[df_start['ca'] != '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"l4\"></a>\n",
    "### Lösung  Aufgabe 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique Elemente zeigen\n",
    "df_no_missing_1['thal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anzeigen wie viele '?' es hat\n",
    "len(df_no_missing_1[df_no_missing_1['thal'] == '?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '?' rausfiltern\n",
    "df_no_missing_2 = df_no_missing_1[df_no_missing_1['thal'] != '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"l5\"></a>\n",
    "### Lösung  Aufgabe 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(X,\n",
    "                           columns=['cp',\n",
    "                                    'restecg',\n",
    "                                    'slope',\n",
    "                                    'thal'],\n",
    "                            dtype=int)\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"l6\"></a>\n",
    "### Lösung Aufgabe 6\n",
    "\n",
    "Die folgenden Code-Zellen bilden eine mögliche Lösung zu Aufgabe 6 ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.00557903\n",
    "value_alpha = 0.0000000000001\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_1 = DecisionTreeClassifier(random_state=0,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_1.fit(X_train, y_train)\n",
    "\n",
    "# plote den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_1,\n",
    "          filled=True,\n",
    "          class_names=[\"No HD\", \"Yes HD\"],\n",
    "          feature_names=list(X_encoded.columns))\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.00557903\n",
    "value_alpha = 0.01425422\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_2 = DecisionTreeClassifier(random_state=0,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_2.fit(X_train, y_train)\n",
    "\n",
    "# plote den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_2,\n",
    "          filled=True,\n",
    "          class_names=[\"No HD\", \"Yes HD\"],\n",
    "          feature_names=list(X_encoded.columns))\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir konstruieren jetzt einen Tree mit 'alpha' = 0.00557903\n",
    "value_alpha = 0.2\n",
    "\n",
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_3 = DecisionTreeClassifier(random_state=0,\n",
    "                                ccp_alpha=value_alpha)\n",
    "clf_dt_3.fit(X_train, y_train)\n",
    "\n",
    "# plote den Entscheidungsbaum\n",
    "plot_tree(decision_tree=clf_dt_3,\n",
    "          filled=True,\n",
    "          class_names=[\"No HD\", \"Yes HD\"],\n",
    "          feature_names=list(X_encoded.columns))\n",
    "\n",
    "# plt.show() zeigt den Plot auf dem Bildschirm an\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"l7\"></a>\n",
    "### Lösung Aufabe 7\n",
    "Die folgenden Code-Zellen bilden eine mögliche Lösung zu Aufgabe 7 ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasifizierungen\n",
    "predictions = clf_dt_1.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt.classes_)\n",
    "\n",
    "# ploten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['Does not have HD', 'Has HD'])\n",
    "\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasifizierungen\n",
    "predictions = clf_dt_2.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt.classes_)\n",
    "\n",
    "# ploten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['Does not have HD', 'Has HD'])\n",
    "\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasifizierungen\n",
    "predictions = clf_dt_3.predict(X_test)\n",
    "cm = confusion_matrix(y_true=y_test,\n",
    "                      y_pred=predictions,\n",
    "                      labels=clf_dt.classes_)\n",
    "\n",
    "# ploten der Confusion-Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['Does not have HD', 'Has HD'])\n",
    "\n",
    "# .plot() plotet die Visualisierung\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"l8\"></a>\n",
    "### Lösung Aufabe 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrected_alpha = ccp_alphas[-4]\n",
    "\n",
    "# # definiere den Entscheidungsbaum\n",
    "# clf_dt_pruned = DecisionTreeClassifier(random_state=0,\n",
    "#                                        ccp_alpha=corrected_alpha)\n",
    "# clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiere den Entscheidungsbaum\n",
    "clf_dt_pruned = DecisionTreeClassifier(random_state=0,\n",
    "                                       ccp_alpha=alpha_opt)\n",
    "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotte den Entscheidungsbaum\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "plot_tree(clf_dt_pruned,\n",
    "          filled=True,\n",
    "          class_names=[\"No HD\", \"Yes HD\"],\n",
    "          feature_names=list(X_encoded.columns))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Accuracy' des einfachen Entscheidungsbaumes\n",
    "# Accuracy = (26 + 31) / (26 + 31 + 7 + 11) = 0.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Accuracy' des neuen Entscheidungsbaumes\n",
    "predictions_new = clf_dt_pruned.predict(X_test)\n",
    "accuracy_score(y_true=y_test,\n",
    "               y_pred=predictions_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
